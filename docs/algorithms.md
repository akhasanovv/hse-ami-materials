---
comments: true
---

# **algorithms**

## **Лекция 1**

### **Асимптотика**

Далее немного матана. Определяем штуки вроде о-малого и О-большого, теты и омеги. 

$t(n) = O(f(n))$ если $\exists C > 0, N$, т.ч. $\forall n > N \ t(n) \le C \cdot f(n)$

$t(n) = o(f(n))$ если $\forall C > 0 \ \exists N$, т.ч. $\forall n > N \ t(n) \le C \cdot f(n)$

$t(n) = \Omega(f(n))$ если $\exists C > 0, N$, т.ч. $\forall n > N \ t(n) \ge C \cdot f(n)$

$t(n) = \omega(f(n))$ если $\forall C > 0 \ \exists N$, т.ч. $\forall n > N \ t(n) \ge C \cdot f(n)$

$\Theta (n) = O(n) + \Omega(n)$

Существуют 3 типа алгоритмов по времени работы:

1. **Сильнополиномиальные**.
Зависят только от количества чисел. Более формально, 
$t(n) = Poly(n)$, где $n$ - количество чисел.

2. **Слабополиномиальные**.
$t(n, C) = Poly(n, \log C)$. Например: поиск бинпоиском корня числа. 

3. **Псевдополиномиальные**.
$t(n, C) = Poly(n, C)$.

#### **Немного задачек**
  
Для каждого из алгоритмов ниже определите, к какому классу (сильно-, слабо-, псевдополи-
    номиальный, не полиномиальный ни в одном из смыслов) они относятся и выпишите 
    асипмтотическую оценку на время работы.

1. Алгоритм Евклида $-$ слабополиномиальный, работает за $O(\log(\max(a, b)))$. Более формально, он принимает $2$ числа, поэтому
    $t(2, C) = \log(C)$.
2. Алгоритм сортировки подсчётом $-$ псевдополиномиальный, $t(n, c) = O(n + C)$.
3. Выбор максимального числа из последовательности $-$ сильнополиномиальный, поскольку $t(n) = O(n)$.
4. Подсчет суммы цифр числа $-$ слабополиномиальный. $t(1, C) = \log_{10} C = \log C$. 
5. Проверка, правда ли все цифры числа в десятичной системе счисления различны $-$ сильнополиномиальный, работает за $O(1)$.
6. Поиск подмножества с максимальной суммой по модулю $P$ перебором всех подмножеств $-$ экспоненциальный, $t(n, C)=2^n$.
7. Дано $n$ и входная последовательность $a_1, a_2, . . . , a_n, a_i \ge $. 
    Алгоритм перебирает все последовательности $b_1, b_2, . . . , b_n$, где $1 \le b_i \le a_i$.
    Не подходит ни под одно определение, $t(n, C) =C^n$ в худшем случае. 

### **Теория вероятностей**

Введем обозначения:

1. $\Omega$ $-$ *конечное* вероятностное пространство; множество элементарных исходов 
    $\Omega = \{w_1, \dots, w_n\}$
2. $2^{\Omega}$ $-$ множество различных исходов, состоящих из какого-то количества элементарных исходов
3. $P$ $-$ функция вероятности
    $P(w_i) \ (0 \le P(w_i) \le 1)$ - вероятность $i$-го элементарного исхода 
    $\sum \limits_{i=1}^n P(w_i) = 1$


И еще немного пределений:

1. Событие $i$ называется *достоверным*, если $P(w_i)=1$.
2. Событие $i$ называется *невозможным*, если $P(w_i)=0$. 
3. События $A$ и $B$ называются *независимыми*, если $P(A) \cdot P(B) = P(A \cap B)$.
4. Набор событий $A_1, \dots, A_k$ называется *независимым в совокупности*, если для любого 
    набора $i_1, \dots, i_l$ выполняется
    $P(A_{i_1} \cap \dots \cap A_{i_l}) = \prod \limits_{j=1}^l P(A_{i_j})$.
5. Вероятность события $A$ при условии выполнения $B$ обозначается как $P(A | B) = \frac{P(A \cap B)}{P(B)}$. 
    Если $A, B$ $-$ независимы, то выполняется $P(A | B) = \frac{P(A) \cdot P(B)}{P(B)} = P(A)$.
6. События $A_1, \dots, A_k$ *образуют полную группу событий* тогда и только тогда, когда $\forall i, j \ (i \ne j) \ A_i \cap A_j=\varnothing$
     и $A_1 \cup \dots \cup A_k = \Omega$.

Для полной группы событий выполняется 

$$P(B) = \sum \limits_{i=1}^k P(B | A_i) \cdot P(A_i) = 
\sum \limits_{i=1}^k \frac{P(A_i \cap B)}{P(A_i)} \cdot P(A_i) = 
\sum \limits_{i=1}^k P(A_i \cap B) = P(\Omega \cap B)$$